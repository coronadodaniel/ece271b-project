2019-03-02 23:19:04,182 - netlog - INFO - ================================================
2019-03-02 23:19:04,182 - netlog - INFO - Learning Rate: 0.0001
2019-03-02 23:19:04,182 - netlog - INFO - Nbr of Epochs: 20
2019-03-02 23:19:04,182 - netlog - INFO - Batch Size: 16
2019-03-02 23:19:04,182 - netlog - INFO - Window Size: 12
2019-03-02 23:19:04,182 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-02 23:20:12,694 - netlog - INFO - ================================================
2019-03-02 23:20:12,694 - netlog - INFO - Learning Rate: 0.0001
2019-03-02 23:20:12,694 - netlog - INFO - Nbr of Epochs: 20
2019-03-02 23:20:12,695 - netlog - INFO - Batch Size: 8
2019-03-02 23:20:12,695 - netlog - INFO - Window Size: 12
2019-03-02 23:20:12,695 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-02 23:20:24,821 - netlog - INFO - epochs:0, train loss:2.48537802696, train acc:12.5
2019-03-02 23:27:58,254 - netlog - INFO - epochs:0, train loss:1.99986338615, train acc:62.5
2019-03-03 00:05:03,949 - netlog - INFO - ================================================
2019-03-03 00:05:03,949 - netlog - INFO - Learning Rate: 0.0001
2019-03-03 00:05:03,949 - netlog - INFO - Nbr of Epochs: 20
2019-03-03 00:05:03,949 - netlog - INFO - Batch Size: 16
2019-03-03 00:05:03,949 - netlog - INFO - Window Size: 10
2019-03-03 00:05:03,949 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-03 00:05:16,552 - netlog - INFO - epochs:0, train loss:2.43735384941, train acc:12.5
2019-03-03 00:16:07,776 - netlog - INFO - ==> val loss:18.75, val acc:2.12809371948
2019-03-03 00:16:17,177 - netlog - INFO - epochs:1, train loss:1.61974310875, train acc:75.0
2019-03-03 00:27:13,915 - netlog - INFO - ==> val loss:18.75, val acc:2.12286829948
2019-03-03 00:27:20,482 - netlog - INFO - epochs:2, train loss:1.27048230171, train acc:100.0
2019-03-03 00:37:43,310 - netlog - INFO - ================================================
2019-03-03 00:37:43,310 - netlog - INFO - Learning Rate: 0.0001
2019-03-03 00:37:43,310 - netlog - INFO - Nbr of Epochs: 20
2019-03-03 00:37:43,310 - netlog - INFO - Batch Size: 16
2019-03-03 00:37:43,310 - netlog - INFO - Window Size: 10
2019-03-03 00:37:43,310 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-03 00:37:56,508 - netlog - INFO - epochs:0, train loss:2.39071726799, train acc:18.75
2019-03-03 00:48:45,023 - netlog - INFO - ==> val loss:50.0, val acc:2.02294874191
2019-03-03 00:48:54,321 - netlog - INFO - epochs:1, train loss:1.92138361931, train acc:50.0
2019-03-03 00:59:43,640 - netlog - INFO - ==> val loss:56.25, val acc:1.77773690224
2019-03-03 00:59:52,859 - netlog - INFO - epochs:2, train loss:1.48983764648, train acc:81.25
2019-03-03 01:10:45,809 - netlog - INFO - ==> val loss:62.5, val acc:1.51448071003
2019-03-03 01:10:55,325 - netlog - INFO - epochs:3, train loss:1.13149940968, train acc:100.0
2019-03-03 01:21:57,487 - netlog - INFO - ==> val loss:81.25, val acc:1.30357289314
2019-03-03 01:22:07,093 - netlog - INFO - epochs:4, train loss:0.94339299202, train acc:100.0
2019-03-03 01:33:06,021 - netlog - INFO - ==> val loss:81.25, val acc:1.22703242302
2019-03-03 01:33:12,641 - netlog - INFO - epochs:5, train loss:0.852302670479, train acc:93.75
2019-03-03 01:44:13,195 - netlog - INFO - ==> val loss:81.25, val acc:1.07502448559
2019-03-03 01:44:19,429 - netlog - INFO - epochs:6, train loss:0.64160823822, train acc:100.0
2019-03-03 01:55:19,397 - netlog - INFO - ==> val loss:81.25, val acc:0.909979462624
2019-03-03 01:55:25,852 - netlog - INFO - epochs:7, train loss:0.567563652992, train acc:100.0
2019-03-03 02:06:24,815 - netlog - INFO - ==> val loss:87.5, val acc:0.760528683662
2019-03-03 02:06:34,167 - netlog - INFO - epochs:8, train loss:0.479961037636, train acc:100.0
2019-03-03 02:17:36,201 - netlog - INFO - ==> val loss:75.0, val acc:0.935729980469
2019-03-03 02:17:42,706 - netlog - INFO - epochs:9, train loss:0.436390221119, train acc:100.0
2019-03-03 02:28:41,480 - netlog - INFO - ==> val loss:81.25, val acc:0.688186943531
2019-03-03 02:28:48,025 - netlog - INFO - epochs:10, train loss:0.382526934147, train acc:100.0
2019-03-03 02:39:45,880 - netlog - INFO - ==> val loss:87.5, val acc:0.656334161758
2019-03-03 02:39:52,109 - netlog - INFO - epochs:11, train loss:0.32490119338, train acc:100.0
2019-03-03 02:50:52,665 - netlog - INFO - ==> val loss:81.25, val acc:0.887809634209
2019-03-03 02:50:59,148 - netlog - INFO - epochs:12, train loss:0.292276740074, train acc:100.0
2019-03-03 03:02:01,165 - netlog - INFO - ==> val loss:75.0, val acc:0.871234536171
2019-03-03 03:02:07,672 - netlog - INFO - epochs:13, train loss:0.272403210402, train acc:100.0
2019-03-03 03:13:08,591 - netlog - INFO - ==> val loss:81.25, val acc:0.758051753044
2019-03-03 03:13:15,298 - netlog - INFO - epochs:14, train loss:0.235805049539, train acc:100.0
2019-03-03 03:24:14,399 - netlog - INFO - ==> val loss:87.5, val acc:0.625538051128
2019-03-03 03:24:20,963 - netlog - INFO - epochs:15, train loss:0.210230007768, train acc:100.0
2019-03-03 03:35:21,323 - netlog - INFO - ==> val loss:81.25, val acc:0.952949285507
2019-03-03 03:35:27,837 - netlog - INFO - epochs:16, train loss:0.223281115294, train acc:100.0
2019-03-03 03:46:23,556 - netlog - INFO - ==> val loss:81.25, val acc:0.828365385532
2019-03-03 03:46:29,894 - netlog - INFO - epochs:17, train loss:0.20938590169, train acc:100.0
2019-03-03 03:57:31,415 - netlog - INFO - ==> val loss:81.25, val acc:0.665566325188
2019-03-03 03:57:37,712 - netlog - INFO - epochs:18, train loss:0.18955129385, train acc:100.0
2019-03-03 04:08:37,979 - netlog - INFO - ==> val loss:81.25, val acc:0.807346642017
2019-03-03 04:08:44,310 - netlog - INFO - epochs:19, train loss:0.182520136237, train acc:100.0
2019-03-03 04:19:41,910 - netlog - INFO - ==> val loss:87.5, val acc:0.491137474775
2019-03-03 04:22:58,746 - netlog - INFO - ==> test loss:77.0700636943, test acc:0.832595229149
