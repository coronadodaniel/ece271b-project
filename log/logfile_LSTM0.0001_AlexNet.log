2019-03-02 23:19:04,182 - netlog - INFO - ================================================
2019-03-02 23:19:04,182 - netlog - INFO - Learning Rate: 0.0001
2019-03-02 23:19:04,182 - netlog - INFO - Nbr of Epochs: 20
2019-03-02 23:19:04,182 - netlog - INFO - Batch Size: 16
2019-03-02 23:19:04,182 - netlog - INFO - Window Size: 12
2019-03-02 23:19:04,182 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-02 23:20:12,694 - netlog - INFO - ================================================
2019-03-02 23:20:12,694 - netlog - INFO - Learning Rate: 0.0001
2019-03-02 23:20:12,694 - netlog - INFO - Nbr of Epochs: 20
2019-03-02 23:20:12,695 - netlog - INFO - Batch Size: 8
2019-03-02 23:20:12,695 - netlog - INFO - Window Size: 12
2019-03-02 23:20:12,695 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-02 23:20:24,821 - netlog - INFO - epochs:0, train loss:2.48537802696, train acc:12.5
2019-03-02 23:27:58,254 - netlog - INFO - epochs:0, train loss:1.99986338615, train acc:62.5
2019-03-03 00:05:03,949 - netlog - INFO - ================================================
2019-03-03 00:05:03,949 - netlog - INFO - Learning Rate: 0.0001
2019-03-03 00:05:03,949 - netlog - INFO - Nbr of Epochs: 20
2019-03-03 00:05:03,949 - netlog - INFO - Batch Size: 16
2019-03-03 00:05:03,949 - netlog - INFO - Window Size: 10
2019-03-03 00:05:03,949 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-03 00:05:16,552 - netlog - INFO - epochs:0, train loss:2.43735384941, train acc:12.5
2019-03-03 00:16:07,776 - netlog - INFO - ==> val loss:18.75, val acc:2.12809371948
2019-03-03 00:16:17,177 - netlog - INFO - epochs:1, train loss:1.61974310875, train acc:75.0
2019-03-03 00:27:13,915 - netlog - INFO - ==> val loss:18.75, val acc:2.12286829948
2019-03-03 00:27:20,482 - netlog - INFO - epochs:2, train loss:1.27048230171, train acc:100.0
2019-03-03 00:37:43,310 - netlog - INFO - ================================================
2019-03-03 00:37:43,310 - netlog - INFO - Learning Rate: 0.0001
2019-03-03 00:37:43,310 - netlog - INFO - Nbr of Epochs: 20
2019-03-03 00:37:43,310 - netlog - INFO - Batch Size: 16
2019-03-03 00:37:43,310 - netlog - INFO - Window Size: 10
2019-03-03 00:37:43,310 - netlog - INFO - Hidden Layer Dimension: 64
2019-03-03 00:37:56,508 - netlog - INFO - epochs:0, train loss:2.39071726799, train acc:18.75
2019-03-03 00:48:45,023 - netlog - INFO - ==> val loss:50.0, val acc:2.02294874191
2019-03-03 00:48:54,321 - netlog - INFO - epochs:1, train loss:1.92138361931, train acc:50.0
2019-03-03 00:59:43,640 - netlog - INFO - ==> val loss:56.25, val acc:1.77773690224
2019-03-03 00:59:52,859 - netlog - INFO - epochs:2, train loss:1.48983764648, train acc:81.25
2019-03-03 01:10:45,809 - netlog - INFO - ==> val loss:62.5, val acc:1.51448071003
2019-03-03 01:10:55,325 - netlog - INFO - epochs:3, train loss:1.13149940968, train acc:100.0
2019-03-03 01:21:57,487 - netlog - INFO - ==> val loss:81.25, val acc:1.30357289314
2019-03-03 01:22:07,093 - netlog - INFO - epochs:4, train loss:0.94339299202, train acc:100.0
2019-03-03 01:33:06,021 - netlog - INFO - ==> val loss:81.25, val acc:1.22703242302
2019-03-03 01:33:12,641 - netlog - INFO - epochs:5, train loss:0.852302670479, train acc:93.75
2019-03-03 01:44:13,195 - netlog - INFO - ==> val loss:81.25, val acc:1.07502448559
2019-03-03 01:44:19,429 - netlog - INFO - epochs:6, train loss:0.64160823822, train acc:100.0
2019-03-03 01:55:19,397 - netlog - INFO - ==> val loss:81.25, val acc:0.909979462624
2019-03-03 01:55:25,852 - netlog - INFO - epochs:7, train loss:0.567563652992, train acc:100.0
2019-03-03 02:06:24,815 - netlog - INFO - ==> val loss:87.5, val acc:0.760528683662
2019-03-03 02:06:34,167 - netlog - INFO - epochs:8, train loss:0.479961037636, train acc:100.0
2019-03-03 02:17:36,201 - netlog - INFO - ==> val loss:75.0, val acc:0.935729980469
2019-03-03 02:17:42,706 - netlog - INFO - epochs:9, train loss:0.436390221119, train acc:100.0
2019-03-03 02:28:41,480 - netlog - INFO - ==> val loss:81.25, val acc:0.688186943531
2019-03-03 02:28:48,025 - netlog - INFO - epochs:10, train loss:0.382526934147, train acc:100.0
2019-03-03 02:39:45,880 - netlog - INFO - ==> val loss:87.5, val acc:0.656334161758
2019-03-03 02:39:52,109 - netlog - INFO - epochs:11, train loss:0.32490119338, train acc:100.0
2019-03-03 02:50:52,665 - netlog - INFO - ==> val loss:81.25, val acc:0.887809634209
2019-03-03 02:50:59,148 - netlog - INFO - epochs:12, train loss:0.292276740074, train acc:100.0
2019-03-03 03:02:01,165 - netlog - INFO - ==> val loss:75.0, val acc:0.871234536171
2019-03-03 03:02:07,672 - netlog - INFO - epochs:13, train loss:0.272403210402, train acc:100.0
2019-03-03 03:13:08,591 - netlog - INFO - ==> val loss:81.25, val acc:0.758051753044
2019-03-03 03:13:15,298 - netlog - INFO - epochs:14, train loss:0.235805049539, train acc:100.0
2019-03-03 03:24:14,399 - netlog - INFO - ==> val loss:87.5, val acc:0.625538051128
2019-03-03 03:24:20,963 - netlog - INFO - epochs:15, train loss:0.210230007768, train acc:100.0
2019-03-03 03:35:21,323 - netlog - INFO - ==> val loss:81.25, val acc:0.952949285507
2019-03-03 03:35:27,837 - netlog - INFO - epochs:16, train loss:0.223281115294, train acc:100.0
2019-03-03 03:46:23,556 - netlog - INFO - ==> val loss:81.25, val acc:0.828365385532
2019-03-03 03:46:29,894 - netlog - INFO - epochs:17, train loss:0.20938590169, train acc:100.0
2019-03-03 03:57:31,415 - netlog - INFO - ==> val loss:81.25, val acc:0.665566325188
2019-03-03 03:57:37,712 - netlog - INFO - epochs:18, train loss:0.18955129385, train acc:100.0
2019-03-03 04:08:37,979 - netlog - INFO - ==> val loss:81.25, val acc:0.807346642017
2019-03-03 04:08:44,310 - netlog - INFO - epochs:19, train loss:0.182520136237, train acc:100.0
2019-03-03 04:19:41,910 - netlog - INFO - ==> val loss:87.5, val acc:0.491137474775
2019-03-03 04:22:58,746 - netlog - INFO - ==> test loss:77.0700636943, test acc:0.832595229149
2019-03-16 14:25:04,902 - netlog - INFO - ================================================
2019-03-16 14:25:04,902 - netlog - INFO - Learning Rate: 0.0001
2019-03-16 14:25:04,902 - netlog - INFO - Nbr of Epochs: 20
2019-03-16 14:25:04,902 - netlog - INFO - Batch Size: 32
2019-03-16 14:25:04,902 - netlog - INFO - Window Size: 25
2019-03-16 14:25:04,902 - netlog - INFO - Hidden Layer Dimension: 128
2019-03-16 14:25:04,902 - netlog - INFO - GPU num: 2
2019-03-16 14:25:38,759 - netlog - INFO - epochs:0, train loss:2.45854997635, train acc:3.125
2019-03-16 14:40:28,748 - netlog - INFO - ==> val loss:1.7214384079, val acc:46.875
2019-03-16 14:40:49,543 - netlog - INFO - epochs:1, train loss:1.52854704857, train acc:81.25
2019-03-16 14:55:32,431 - netlog - INFO - ==> val loss:1.47622513771, val acc:75.0
2019-03-16 14:55:53,477 - netlog - INFO - epochs:2, train loss:1.07095706463, train acc:93.75
2019-03-16 15:10:38,527 - netlog - INFO - ==> val loss:1.30430436134, val acc:75.0
2019-03-16 15:10:56,550 - netlog - INFO - epochs:3, train loss:0.766958117485, train acc:100.0
2019-03-16 15:25:47,988 - netlog - INFO - ==> val loss:1.2552164793, val acc:68.75
2019-03-16 15:26:05,966 - netlog - INFO - epochs:4, train loss:0.607408344746, train acc:100.0
2019-03-16 15:40:54,278 - netlog - INFO - ==> val loss:1.3345400095, val acc:62.5
2019-03-16 15:41:11,995 - netlog - INFO - epochs:5, train loss:0.484960705042, train acc:100.0
2019-03-16 15:56:01,391 - netlog - INFO - ==> val loss:1.24467515945, val acc:68.75
2019-03-16 15:56:19,315 - netlog - INFO - epochs:6, train loss:0.399456202984, train acc:100.0
2019-03-16 16:11:09,392 - netlog - INFO - ==> val loss:1.08383822441, val acc:75.0
2019-03-16 16:11:27,818 - netlog - INFO - epochs:7, train loss:0.357035517693, train acc:100.0
2019-03-16 16:26:14,908 - netlog - INFO - ==> val loss:1.19342958927, val acc:65.625
2019-03-16 16:26:33,119 - netlog - INFO - epochs:8, train loss:0.278323590755, train acc:100.0
2019-03-16 16:41:23,221 - netlog - INFO - ==> val loss:0.977098703384, val acc:78.125
2019-03-16 16:41:44,456 - netlog - INFO - epochs:9, train loss:0.229529216886, train acc:100.0
2019-03-16 16:56:35,199 - netlog - INFO - ==> val loss:0.994248151779, val acc:75.0
2019-03-16 16:56:53,425 - netlog - INFO - epochs:10, train loss:0.193262338638, train acc:100.0
2019-03-16 17:11:42,168 - netlog - INFO - ==> val loss:0.992770135403, val acc:75.0
2019-03-16 17:12:00,389 - netlog - INFO - epochs:11, train loss:0.19399818778, train acc:100.0
2019-03-16 17:26:47,443 - netlog - INFO - ==> val loss:1.05677556992, val acc:71.875
2019-03-16 17:27:05,364 - netlog - INFO - epochs:12, train loss:0.148464530706, train acc:100.0
2019-03-16 17:41:53,266 - netlog - INFO - ==> val loss:0.890578091145, val acc:75.0
2019-03-16 17:42:11,093 - netlog - INFO - epochs:13, train loss:0.126493826509, train acc:100.0
2019-03-16 17:56:58,576 - netlog - INFO - ==> val loss:0.971963703632, val acc:78.125
2019-03-16 17:57:16,720 - netlog - INFO - epochs:14, train loss:0.123452626169, train acc:100.0
2019-03-16 18:12:07,210 - netlog - INFO - ==> val loss:1.14385843277, val acc:68.75
2019-03-16 18:12:25,547 - netlog - INFO - epochs:15, train loss:0.123394496739, train acc:100.0
2019-03-16 18:27:17,181 - netlog - INFO - ==> val loss:1.11058759689, val acc:68.75
2019-03-16 18:27:35,109 - netlog - INFO - epochs:16, train loss:0.112886019051, train acc:100.0
2019-03-16 18:42:26,445 - netlog - INFO - ==> val loss:1.12724637985, val acc:75.0
2019-03-16 18:42:44,275 - netlog - INFO - epochs:17, train loss:0.104880511761, train acc:100.0
2019-03-16 18:57:31,978 - netlog - INFO - ==> val loss:1.23273909092, val acc:68.75
2019-03-16 18:57:50,026 - netlog - INFO - epochs:18, train loss:0.0915048494935, train acc:100.0
2019-03-16 19:12:36,229 - netlog - INFO - ==> val loss:1.0677344799, val acc:71.875
2019-03-16 19:12:53,819 - netlog - INFO - epochs:19, train loss:0.0836383402348, train acc:100.0
2019-03-16 19:27:44,939 - netlog - INFO - ==> val loss:1.04556071758, val acc:71.875
2019-03-16 19:32:01,720 - netlog - INFO - ==> test loss:0.967254757881, test acc:72.8237791932
